dataset:
  num_classes: 20
  training:
    video_mp4_path: ./datasets/thumos14/validation/
    video_info_path: thumos_annotations/val_video_info.csv
    video_anno_path: thumos_annotations/val_Annotation_ours.csv
    video_data_path: ./datasets/thumos14/validation_flow_npy/
    clip_length: 256
    clip_stride: 30
    crop_size: 96
  testing:
    video_mp4_path: ./datasets/thumos14/test/
    video_info_path: thumos_annotations/test_video_info.csv
    video_anno_path: thumos_annotations/test_Annotation_ours.csv
    video_data_path: ./datasets/thumos14/test_flow_npy/
    crop_size: 96
    clip_length: 256
    clip_stride: 128

model:
  in_channels: 2
  freeze_bn: true
  freeze_bn_affine: true
  backbone_model: ./models/i3d_models/flow_imagenet.pt
  featmap_strides: [4, 8, 16, 32, 64, 128]

  model_type: BEMModule  # (BaseModel | BEMModule)
  deform_conv_grad_mul: 0.1 # locs grad
  use_quality_1: True
  head:
    # detection head type: `2stage_g` (REM) or `base`
    type: 2stage_g
    channel: 512
  prop_g_args:
    use_offset: True
    use_confs: True
    use_q: True
  # cfg of BEM
  BEM:
    num_sample: 14
    in_ratio: 4
    out_ratio: 4
    param_init: default  # (default|normal)
    windows_ratio: 0.0
    windows_num: 20
    map_type: adaptive_050
    reduction_type: max
    dim_fpn: 1024
    dim_conv: 512
    lambda_1: 50
    # windows select in training phase
    use_mask: True
    match_topk: 2

training:
  batch_size: 1
  learning_rate: 1e-5
  weight_decay: 1e-3
  max_epoch: 16
  focal_loss: true
  checkpoint_path: ./models/thumos14_flow/
  random_seed: 2020
  piou: 0.5

testing:
  conf_thresh: 0.01
  top_k: 5000
  nms_thresh: 0.5
  nms_sigma: 0.5
  checkpoint_path: ./models/thumos14_flow/checkpoint-16.ckpt
  output_path: ./output
  output_json: detection_results.json